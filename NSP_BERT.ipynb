{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1a8ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "import torch\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4a30527",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed99a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/clean.txt','r') as fp:\n",
    "    text = fp.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02045c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From my grandfather Verus I learned good morals and the government of my temper.',\n",
       " 'From the reputation and remembrance of my father, modesty and a manly character.',\n",
       " 'From my mother, piety and beneficence, and abstinence, not only from evil deeds, but even from evil thoughts; and further, simplicity in my way of living, far removed from the habits of the rich.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0313c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = [sentence for para in text for sentence in para.split('.') if sentence !='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "853a5cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_size = len(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6219f7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1372"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d8f41ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sentence_a = []\n",
    "sentence_b = []\n",
    "label =[]\n",
    "for paragraph in text:\n",
    "    sentences =[\n",
    "        sentence for sentence in paragraph.split('.') if sentence !=''\n",
    "    ]\n",
    "    num_sentences = len(sentences)\n",
    "    if num_sentences >1:\n",
    "        start = random.randint(0,num_sentences-2)\n",
    "        sentence_a.append(sentences[start])\n",
    "        if random.random() > 0.5:\n",
    "            sentence_b.append(bag[random.randint(0,bag_size-1)])\n",
    "            label.append(1)\n",
    "        else:\n",
    "            sentence_b.append(sentences[start+1])\n",
    "            label.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e8f494e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      " He was accustomed to do acts of beneficence, and was ready to forgive, and was free from all falsehood; and he presented the appearance of a man who could not be diverted from right rather than of a man who had been improved\n",
      "---\n",
      " I observed, too, that no man could ever think that he was despised by Maximus, or ever venture to think himself a better man\n",
      "---\n",
      "1\n",
      " There was in him nothing harsh, nor implacable, nor violent, nor, as one may say, anything carried to the sweating point; but he examined all things severally, as if he had abundance of time, and without confusion, in an orderly way, vigorously and consistently\n",
      "---\n",
      "About fame: Look at the minds of those who seek fame, observe what they are, and what kind of things they avoid, and what kind of things they pursue\n",
      "---\n",
      "1\n",
      "To the gods I am indebted for having good grandfathers, good parents, a good sister, good teachers, good associates, good kinsmen and friends, nearly everything good\n",
      "---\n",
      " But if usage has especially fixed these terms to the vine and like things, this is nothing\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(label[i])\n",
    "    print(sentence_a[i] + '\\n---')\n",
    "    print(sentence_b[i] + '\\n---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "229eca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(sentence_a,sentence_b,return_tensors='pt',max_length=512,truncation=True,padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4dea034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b8774a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2002,  2001,  ...,     0,     0,     0],\n",
       "        [  101,  2045,  2001,  ...,     0,     0,     0],\n",
       "        [  101,  2000,  1996,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  3459,  2185,  ...,     0,     0,     0],\n",
       "        [  101,  2043, 15223,  ...,     0,     0,     0],\n",
       "        [  101,  7887,  3288,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67c26d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['labels'] = torch.LongTensor(label).unsqueeze(0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2cb11ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeditationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,encodings):\n",
    "        self.encodings = encodings\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        return{key: tensor[idx] for key,tensor in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return self.encodings.input_ids.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ceda9a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MeditationDataset(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "560abc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset,batch_size=2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "56084b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manik\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "optim = AdamW(model.parameters(),lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "df252fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0: 100%|██████████| 159/159 [32:15<00:00, 12.17s/it, loss=1.06] \n",
      "epoch 1: 100%|██████████| 159/159 [33:01<00:00, 12.46s/it, loss=0.845] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "epochs =2 \n",
    "for epoch in range(epochs):\n",
    "    loop = tqdm(dataloader,leave=True)\n",
    "    for batch in loop:\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        outputs = model(input_ids,attention_mask = attention_mask,labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        loop.set_description(f'epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc11d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
